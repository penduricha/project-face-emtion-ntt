{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6480,
     "status": "ok",
     "timestamp": 1768371086359,
     "user": {
      "displayName": "Quang Nháº­t Tá»«",
      "userId": "10885604408615433577"
     },
     "user_tz": -420
    },
    "id": "evAJm0IK4ru8"
   },
   "outputs": [],
   "source": [
    "# !pip install -q insightface onnxruntime-gpu deepface opencv-python gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33991,
     "status": "ok",
     "timestamp": 1768371120353,
     "user": {
      "displayName": "Quang Nháº­t Tá»«",
      "userId": "10885604408615433577"
     },
     "user_tz": -420
    },
    "id": "z1p2iIrC44vZ",
    "outputId": "f282b081-8013-4939-e990-6ba8d566deb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26-01-14 06:11:55 - Directory /root/.deepface has been created\n",
      "26-01-14 06:11:55 - Directory /root/.deepface/weights has been created\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from deepface import DeepFace\n",
    "from insightface.app import FaceAnalysis\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15746,
     "status": "ok",
     "timestamp": 1768371136101,
     "user": {
      "displayName": "Quang Nháº­t Tá»«",
      "userId": "10885604408615433577"
     },
     "user_tz": -420
    },
    "id": "1QXsc8E65NHy",
    "outputId": "93bf6aa8-5835-4714-f690-d8d1190d271e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_path: /root/.insightface/models/buffalo_l\n",
      "Downloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281857/281857 [00:09<00:00, 31091.37KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: /root/.insightface/models/buffalo_l/genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "# CÃ i Ä‘áº·t mÃ´ hÃ¬nh\n",
    "face_app = FaceAnalysis(allowed_modules=['detection'])\n",
    "face_app.prepare(ctx_id=0, det_size=(640, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1768371136109,
     "user": {
      "displayName": "Quang Nháº­t Tá»«",
      "userId": "10885604408615433577"
     },
     "user_tz": -420
    },
    "id": "LMe4BPNB8NRp"
   },
   "outputs": [],
   "source": [
    "def analyze_face_emotion(input_img):\n",
    "    if input_img is None:\n",
    "        return None, \"Vui lÃ²ng chá»n má»™t hÃ¬nh áº£nh!\"\n",
    "    img = cv2.cvtColor(np.array(input_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    faces = face_app.get(img)\n",
    "    if not faces:\n",
    "        return None, \"KhÃ´ng tÃ¬m tháº¥y gÆ°Æ¡ng máº·t nÃ o trong áº£nh.\"\n",
    "\n",
    "    largest_face = max(faces, key=lambda f: (f.bbox[2]-f.bbox[0]) * (f.bbox[3]-f.bbox[1]))\n",
    "    bbox = largest_face.bbox.astype(int)\n",
    "    x1, y1, x2, y2 = bbox\n",
    "\n",
    "    padding = 40\n",
    "    h_img, w_img = img.shape[:2]\n",
    "    x1, y1 = max(0, x1 - padding), max(0, y1 - padding)\n",
    "    x2, y2 = min(w_img, x2 + padding), min(h_img, y2 + padding)\n",
    "    cropped_face = img[y1:y2, x1:x2]\n",
    "\n",
    "    try:\n",
    "        results = DeepFace.analyze(img_path = cropped_face,\n",
    "                                   actions = ['emotion'],\n",
    "                                   enforce_detection = False)\n",
    "        res = results[0]\n",
    "        dominant = res['dominant_emotion']\n",
    "        emotions = res['emotion']\n",
    "        cropped_rgb = cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB)\n",
    "        result_text = f\"### Cáº£m xÃºc chá»§ Ä‘áº¡o: {dominant.upper()}\\n\\n\"\n",
    "        sorted_emotions = dict(sorted(emotions.items(), key=lambda item: item[1], reverse=True))\n",
    "        return cropped_rgb, sorted_emotions\n",
    "    except Exception as e:\n",
    "        return None, f\"Lá»—i phÃ¢n tÃ­ch: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1768371136609,
     "user": {
      "displayName": "Quang Nháº­t Tá»«",
      "userId": "10885604408615433577"
     },
     "user_tz": -420
    },
    "id": "AUY36Hjp5TFB"
   },
   "outputs": [],
   "source": [
    "# XÃ¢y dá»±ng giao diá»‡n Web (CSS + HTML tÃ­ch há»£p sáºµn trong Gradio)\n",
    "with gr.Blocks(theme=gr.themes.Soft(), title=\"AI Emotion Detector\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # Há»‡ Thá»‘ng PhÃ¢n TÃ­ch Cáº£m XÃºc\n",
    "    Táº£i áº£nh lÃªn Ä‘á»ƒ há»‡ thá»‘ng tá»± Ä‘á»™ng nháº­n diá»‡n khuÃ´n máº·t vÃ  phÃ¢n tÃ­ch tráº¡ng thÃ¡i cáº£m xÃºc.\n",
    "    \"\"\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_image = gr.Image(label=\"áº¢nh gá»‘c\", type=\"numpy\")\n",
    "            with gr.Row():\n",
    "                btn_reset = gr.Button(\"LÃ m má»›i\", variant=\"secondary\")\n",
    "                btn_analyze = gr.Button(\"PhÃ¢n TÃ­ch Cáº£m XÃºc\", variant=\"primary\")\n",
    "        with gr.Column():\n",
    "            output_face = gr.Image(label=\"KhuÃ´n máº·t Ä‘Ã£ nháº­n diá»‡n\")\n",
    "            output_chart = gr.Label(label=\"Tá»· lá»‡ cáº£m xÃºc (%)\", num_top_classes=5)\n",
    "    # Xá»­ lÃ½ sá»± kiá»‡n\n",
    "    btn_analyze.click(fn=analyze_face_emotion,\n",
    "                      inputs=input_image,\n",
    "                      outputs=[output_face, output_chart])\n",
    "    btn_reset.click(fn=lambda: [None, None, None],\n",
    "                    inputs=None,\n",
    "                    outputs=[input_image, output_face, output_chart])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "id": "gKRiJ6jjC1Nh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
      "* Running on public URL: https://3abdb69e71d0d124ca.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3abdb69e71d0d124ca.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5\n",
      "To: /root/.deepface/weights/facial_expression_model_weights.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26-01-14 06:14:27 - ðŸ”— facial_expression_model_weights.h5 will be downloaded from https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5 to /root/.deepface/weights/facial_expression_model_weights.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.98M/5.98M [00:00<00:00, 73.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Run web\n",
    "demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP8SZjTBQHXVk+k16YTF1z/",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
